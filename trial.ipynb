{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24dfc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jaina\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfd8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "data_dir = \"./dataset\"   # Path to your dataset\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUG_FACTOR = 10\n",
    "EPOCHS = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "225b634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['normal', 'osteoporosis']\n",
      "Original dataset size: 372\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# LOAD FILES & LABELS\n",
    "# -----------------------------\n",
    "classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "class_to_index = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "all_image_paths, all_labels = [], []\n",
    "for cls in classes:\n",
    "    paths = glob(os.path.join(data_dir, cls, \"*\"))\n",
    "    all_image_paths.extend(paths)\n",
    "    all_labels.extend([class_to_index[cls]] * len(paths))\n",
    "\n",
    "all_image_paths = np.array(all_image_paths)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Original dataset size:\", len(all_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befbc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# NORMALIZATION FUNCTION (Grayscale â†’ RGB)\n",
    "# -----------------------------\n",
    "def normalize_image_rgb(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=1, expand_animations=False)  # grayscale\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.tile(img, [1, 1, 3])  # convert to RGB  #CHANGE\n",
    "    return img, label\n",
    "\n",
    "# -----------------------------\n",
    "# STRONG AUGMENTATION FUNCTION\n",
    "# -----------------------------\n",
    "def augment_image(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    img = tf.image.rot90(img, k=k)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d304ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# BUILD DATASET\n",
    "# -----------------------------\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_labels))\n",
    "dataset = dataset.map(normalize_image_rgb, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e625a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 223\n",
      "Val size  : 74\n",
      "Test size : 75\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# SPLIT TRAIN / VAL / TEST\n",
    "# -----------------------------\n",
    "dataset_size = len(all_image_paths)\n",
    "train_size = int(0.6 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "\n",
    "dataset = dataset.shuffle(dataset_size, reshuffle_each_iteration=False)\n",
    "train_ds = dataset.take(train_size)\n",
    "val_test_ds = dataset.skip(train_size)\n",
    "val_ds = val_test_ds.take(val_size)\n",
    "test_ds = val_test_ds.skip(val_size)\n",
    "\n",
    "print(\"Train size:\", sum(1 for _ in train_ds))\n",
    "print(\"Val size  :\", sum(1 for _ in val_ds))\n",
    "print(\"Test size :\", sum(1 for _ in test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfafd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# AUGMENT TRAINING DATA\n",
    "# -----------------------------\n",
    "train_ds = train_ds.map(augment_image, num_parallel_calls=AUTOTUNE).repeat(AUG_FACTOR)\n",
    "train_ds = train_ds.shuffle(buffer_size=train_size * AUG_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe6a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# BATCH & PREFETCH\n",
    "# -----------------------------\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298c412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "for img, lbl in dataset.take(1): \n",
    "    print(img.shape) # should be (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b111cc99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# MODEL WITH EFFICIENTNETB0\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# CHANGE: Use input_shape=(224,224,3) for RGB (grayscale images converted to 3 channels)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m base_model = \u001b[43mEfficientNetB0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimagenet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pretrained on ImageNet\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# RGB input  #CHANGE\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m base_model.trainable = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# fine-tune base\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ADD CUSTOM CLASSIFIER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\efficientnet.py:571\u001b[39m, in \u001b[36mEfficientNetB0\u001b[39m\u001b[34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[32m    556\u001b[39m     [\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    569\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mefficientnetb0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    570\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\applications\\efficientnet.py:434\u001b[39m, in \u001b[36mEfficientNet\u001b[39m\u001b[34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, weights_name)\u001b[39m\n\u001b[32m    427\u001b[39m     file_name = name + file_suffix\n\u001b[32m    428\u001b[39m     weights_path = file_utils.get_file(\n\u001b[32m    429\u001b[39m         file_name,\n\u001b[32m    430\u001b[39m         BASE_WEIGHTS_PATH + file_name,\n\u001b[32m    431\u001b[39m         cache_subdir=\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         file_hash=file_hash,\n\u001b[32m    433\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    436\u001b[39m     model.load_weights(weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:447\u001b[39m, in \u001b[36m_set_weights\u001b[39m\u001b[34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[39m\n\u001b[32m    437\u001b[39m             warnings.warn(\n\u001b[32m    438\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdue to mismatch in shape for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    445\u001b[39m             )\n\u001b[32m    446\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    448\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i].path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived saved weight \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    453\u001b[39m         )\n\u001b[32m    454\u001b[39m     symbolic_weights[i].assign(weight_value)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33mfinalize_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[31mValueError\u001b[39m: Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# MODEL WITH EFFICIENTNETB0\n",
    "# -----------------------------\n",
    "# CHANGE: Use input_shape=(224,224,3) for RGB (grayscale images converted to 3 channels)\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',  # pretrained on ImageNet\n",
    "    input_shape=(224,224,3)  # RGB input  #CHANGE\n",
    ")\n",
    "base_model.trainable = True  # fine-tune base\n",
    "\n",
    "# ADD CUSTOM CLASSIFIER\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=outputs)  #CHANGE\n",
    "# -----------------------------\n",
    "# COMPILE MODEL\n",
    "# -----------------------------\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# CALLBACKS\n",
    "# -----------------------------\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# TRAIN MODEL\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATE ON TEST SET\n",
    "# -----------------------------\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f13529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# EVALUATION HELPER\n",
    "# -----------------------------\n",
    "def evaluate_and_report(model, dataset, split_name=\"Validation\"):\n",
    "    y_true, y_pred = [], []\n",
    "    for imgs, lbls in dataset:\n",
    "        preds = model.predict(imgs, verbose=0)\n",
    "        y_true.extend(lbls.numpy())\n",
    "        y_pred.extend((preds > 0.5).astype(\"int32\").flatten())\n",
    "\n",
    "    print(f\"\\n{split_name} -> Accuracy:\", np.mean(np.array(y_true) == np.array(y_pred)))\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f\"{split_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# EVALUATE MODEL\n",
    "# -----------------------------\n",
    "evaluate_and_report(model, val_ds, \"Validation\")\n",
    "evaluate_and_report(model, test_ds, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
